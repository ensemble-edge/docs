---
title: "Caching"
description: "Multi-layer caching strategy for performance and cost optimization"
---

## Why Caching Matters

AI and API calls are expensive. Caching the same request can save you **90%+ on costs** and reduce latency from seconds to milliseconds. Conductor provides multi-layer caching out of the box.

<CardGroup cols={2}>
  <Card title="Cost Savings" icon="dollar-sign">
    Cache identical AI requests - pay once, use many times
  </Card>

  <Card title="Speed" icon="bolt">
    Cached responses return in < 5ms vs 1-2 seconds for API calls
  </Card>

  <Card title="Reliability" icon="shield">
    Continue working even if AI providers have outages
  </Card>

  <Card title="Rate Limits" icon="gauge">
    Reduce API calls to stay within provider rate limits
  </Card>
</CardGroup>

## How Caching Works

```mermaid
graph LR
    A[Execute Member] --> B{Check KV Cache}
    B -->|Cache Hit| C[Return Cached Result]
    B -->|Cache Miss| D[Execute Member]
    D --> E[Store in KV Cache]
    E --> F[Return Result]

    style B fill:#4FD1C5
    style C fill:#2D1B69
    style E fill:#E91E8C
```

## Three Caching Layers

Conductor provides three complementary caching layers:

### 1. Member-Level Cache (KV)

Conductor's built-in cache using Cloudflare KV:

```yaml
flow:
  - member: expensive-ai-call
    cache:
      ttl: 3600      # Cache for 1 hour
      bypass: false  # Respect cache (default)
```

**Features:**
- Automatic cache key generation (member name + input hash)
- TTL control per member
- Cache bypass option
- Works across all member types

### 2. AI Gateway Cache

Cloudflare AI Gateway provides persistent caching for AI provider calls:

```yaml
flow:
  - member: generate-summary
    config:
      provider: openai
      model: gpt-4o
      routing: cloudflare-gateway  # Enable AI Gateway
```

**Features:**
- Persistent cache across deployments
- Real-time analytics and monitoring
- Cache hit rate tracking
- Works with OpenAI, Anthropic, Groq, etc.

### 3. Browser Cache (Client-Side)

For web applications, use HTTP cache headers:

```typescript
// API response with cache headers
return new Response(JSON.stringify(result), {
  headers: {
    'Content-Type': 'application/json',
    'Cache-Control': 'public, max-age=300', // 5 minutes
    'ETag': generateETag(result)
  }
});
```

## Member-Level Caching

### Basic Configuration

Enable caching for any member:

```yaml
flow:
  - member: analyze-company
    input:
      domain: ${input.domain}
    cache:
      ttl: 3600  # 1 hour in seconds
```

### Cache Bypass

Skip cache for specific requests:

```yaml
flow:
  - member: get-live-data
    cache:
      ttl: 300
      bypass: ${input.forceRefresh}  # Bypass if user requests fresh data
```

### Cache Key Customization

Conductor automatically generates cache keys from:
- Member name
- Input data (hashed)

**Example automatic key:**
```
conductor:cache:analyze-company:a3f8c50d1e...
```

### Per-Member TTL

Different members can have different cache durations:

```yaml
flow:
  # Long cache - data changes rarely
  - member: fetch-company-profile
    cache:
      ttl: 86400  # 24 hours

  # Medium cache - data changes occasionally
  - member: fetch-company-news
    cache:
      ttl: 3600  # 1 hour

  # Short cache - data changes frequently
  - member: fetch-stock-price
    cache:
      ttl: 60  # 1 minute
```

## AI Gateway Caching

### Setup

Configure AI Gateway in wrangler.toml:

```toml
[ai]
binding = "AI"

[[ai.gateway]]
id = "my-gateway"
cache_ttl = 3600
```

### Usage

Route AI calls through gateway:

```yaml
flow:
  - member: generate-content
    config:
      provider: openai
      model: gpt-4o
      routing: cloudflare-gateway  # Use AI Gateway
      temperature: 0.7
```

### Benefits

<AccordionGroup>
  <Accordion title="Persistent Cache" icon="database">
    Cache survives deployments and spans all Workers. Once cached, every user benefits.
  </Accordion>

  <Accordion title="Analytics" icon="chart-line">
    Track cache hit rates, costs, latency in real-time dashboard.
  </Accordion>

  <Accordion title="Cost Controls" icon="dollar-sign">
    Set spending limits, rate limits, and alerts via dashboard.
  </Accordion>

  <Accordion title="A/B Testing" icon="flask">
    Compare different models, prompts, parameters with traffic splitting.
  </Accordion>
</AccordionGroup>

### Cache Hit Rate Monitoring

```typescript
// AI Gateway provides metrics
const result = await executor.executeEnsemble('analyze-text', input);

// Check if result came from cache
if (result.metadata?.cached) {
  console.log('Cache hit - saved API call!');
}
```

## Caching Strategies

### Time-Based Invalidation

Set TTL based on data freshness requirements:

```yaml
flow:
  # Static data - cache for days
  - member: fetch-company-description
    cache:
      ttl: 604800  # 7 days

  # Dynamic data - cache for minutes
  - member: fetch-trending-topics
    cache:
      ttl: 300  # 5 minutes

  # Real-time data - cache briefly
  - member: fetch-live-metrics
    cache:
      ttl: 10  # 10 seconds
```

### Conditional Caching

Cache only when appropriate:

```yaml
flow:
  - member: generate-report
    cache:
      # Only cache for production data
      ttl: ${input.environment === 'production' ? 3600 : 0}
```

### Layered Caching

Combine multiple cache layers:

```yaml
flow:
  # Layer 1: AI Gateway cache (persistent)
  - member: generate-summary
    config:
      routing: cloudflare-gateway
    cache:
      ttl: 3600  # Layer 2: KV cache

  # Layer 3: HTTP cache headers (client-side)
  # Set in API response
```

### Cache Warming

Pre-populate your cache to ensure fast responses for your users from the first request. Conductor provides both automated and manual cache warming strategies.

#### Automated Cache Warming

Enable automatic cache warming for any member by adding `warming: true` or `prewarm: true` to the cache configuration:

```yaml
flow:
  # Page member with cache warming
  - member: homepage
    type: Page
    cache:
      ttl: 3600
      warming: true  # Auto-warm this route

  # API member with cache warming
  - member: get-pricing
    type: API
    config:
      url: "https://api.example.com/pricing"
    cache:
      ttl: 7200
      prewarm: true  # Alternative syntax

  # Think member with cache warming
  - member: generate-faq
    type: Think
    config:
      provider: openai
      model: gpt-4o
    cache:
      ttl: 86400
      warming: true
```

**How it works:**
- Works with ANY member type (Page, API, Data, Think, Function, HTML, etc.)
- Routes are automatically extracted and warmed during deployment
- Cache is refreshed based on TTL to prevent expiration
- No additional configuration required

#### Priority Ordering

Cache warming executes routes in priority order:

1. **Critical** - Routes with highest traffic/importance
2. **High** - Important routes that benefit from warming
3. **Medium** - Standard routes (default)
4. **Low** - Optional routes

```yaml
flow:
  - member: landing-page
    cache:
      ttl: 3600
      warming: true
      priority: critical  # Warmed first

  - member: product-catalog
    cache:
      ttl: 7200
      warming: true
      priority: high

  - member: blog-archive
    cache:
      ttl: 86400
      warming: true
      priority: low
```

#### NPM Scripts

Use built-in scripts to warm your cache:

```bash
# Warm cache after deployment
npm run deploy:warm

# Warm cache manually anytime
npm run warm-cache

# Warm specific routes
npm run warm-cache -- --routes=/api/pricing,/api/products
```

#### Example Output

```bash
$ npm run warm-cache

Cache Warming Results:
  Critical: 3/3 warmed (100%)
  High: 8/8 warmed (100%)
  Medium: 15/15 warmed (100%)
  Low: 5/5 warmed (100%)

Total: 31/31 routes warmed in 4.2s
Cache coverage: 100%
```

#### Scheduled Cache Refresh

Keep your cache fresh with scheduled refreshes:

```typescript
// src/scheduled.ts
import { scheduledCacheRefresh } from '@ensemble-edge/conductor/utils/cache-warming';

export default {
  async scheduled(event: ScheduledEvent, env: Env, ctx: ExecutionContext) {
    // Refresh cache every 6 hours
    await scheduledCacheRefresh(env, ctx);
  }
};
```

Configure schedule in `wrangler.toml`:

```toml
[triggers]
crons = ["0 */6 * * *"]  # Every 6 hours
```

#### Manual Cache Warming

For programmatic control, use the cache warming utilities directly:

```typescript
import { warmCache, extractWarmableRoutes } from '@ensemble-edge/conductor/utils/cache-warming';

// Extract routes from your ensemble configuration
const routes = extractWarmableRoutes(ensembleConfig);

// Warm all routes
const results = await warmCache(routes, env.BASE_URL);

console.log(`Warmed ${results.success}/${results.total} routes`);

// Warm specific routes
await warmCache([
  { path: '/api/pricing', priority: 'critical' },
  { path: '/api/products', priority: 'high' }
], env.BASE_URL);
```

**Common use cases:**
- Pre-populate cache for frequently accessed endpoints
- Warm cache after content updates
- Ensure fast first-request performance
- Prepare cache before traffic spikes

## Cache Invalidation

### Time-Based (Automatic)

TTL expires and cache entry is removed:

```yaml
cache:
  ttl: 3600  # Automatically expires after 1 hour
```

### Manual Invalidation

Programmatically clear cache:

```typescript
import { KVRepository } from '@ensemble-edge/conductor/storage';

const cache = new KVRepository(env.CACHE);

// Clear specific key
await cache.delete('conductor:cache:analyze-company:a3f8c50...');

// Clear all keys matching pattern (requires list + delete)
const keys = await env.CACHE.list({ prefix: 'conductor:cache:' });
for (const key of keys.keys) {
  await env.CACHE.delete(key.name);
}
```

### Event-Based Invalidation

Invalidate when data changes:

```yaml
flow:
  - member: update-company-data
    input:
      domain: ${input.domain}
      data: ${input.data}

  # Invalidate cached analysis
  - member: invalidate-cache
    input:
      key: analyze-company:${input.domain}
```

```typescript
// members/invalidate-cache/index.ts
export default async function invalidateCache({ input, env }) {
  const key = `conductor:cache:${input.key}`;
  await env.CACHE.delete(key);
  return { invalidated: key };
}
```

### Webhook-Triggered Invalidation

Clear cache when external data changes:

```yaml
webhooks:
  - path: "/data-updated"
    ensemble: invalidate-analysis-cache
    auth:
      type: signature
      secret: ${env.WEBHOOK_SECRET}
```

## Cache Tags

Cache tags enable smart, targeted cache invalidation. Instead of clearing individual cache entries or purging everything, you can invalidate groups of related cache entries using tags.

### Configuration

Add tags to any cached member:

```yaml
flow:
  - member: get-user-profile
    type: API
    config:
      url: "https://api.example.com/users/${input.userId}"
    cache:
      ttl: 3600
      tags:
        - user:${input.userId}
        - profile
        - api

  - member: get-user-posts
    type: API
    config:
      url: "https://api.example.com/users/${input.userId}/posts"
    cache:
      ttl: 1800
      tags:
        - user:${input.userId}
        - posts
        - api

  - member: render-dashboard
    type: Page
    cache:
      ttl: 7200
      tags:
        - user:${input.userId}
        - dashboard
        - ui
```

### Purging by Tag

Invalidate all cache entries with a specific tag using the Cloudflare API:

```typescript
// Purge all cache for a specific user
async function purgeUserCache(userId: string, zoneId: string, apiToken: string) {
  const response = await fetch(
    `https://api.cloudflare.com/client/v4/zones/${zoneId}/purge_cache`,
    {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiToken}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        tags: [`user:${userId}`]
      })
    }
  );

  return response.json();
}

// Purge all API responses
await purgeByTag('api', zoneId, apiToken);

// Purge all dashboard pages
await purgeByTag('dashboard', zoneId, apiToken);
```

### Tag Strategies

#### Hierarchical Tags

Organize tags by levels of granularity:

```yaml
cache:
  ttl: 3600
  tags:
    - org:${input.orgId}                    # Organization level
    - org:${input.orgId}:team:${input.teamId}  # Team level
    - org:${input.orgId}:user:${input.userId}  # User level
```

**Benefits:**
- Purge entire organization: `org:acme-corp`
- Purge specific team: `org:acme-corp:team:engineering`
- Purge specific user: `org:acme-corp:user:john`

#### User-Specific Tags

Track cache entries by user:

```yaml
cache:
  ttl: 3600
  tags:
    - user:${input.userId}
    - user:${input.userId}:preferences
    - user:${input.userId}:session
```

**Use cases:**
- User logs out: Purge `user:${userId}`
- User updates preferences: Purge `user:${userId}:preferences`
- Session expires: Purge `user:${userId}:session`

#### Time-Based Tags

Tag cache entries by time period:

```yaml
cache:
  ttl: 86400
  tags:
    - report
    - report:${input.year}
    - report:${input.year}:${input.month}
    - report:${input.year}:${input.month}:${input.day}
```

**Use cases:**
- Regenerate all reports: Purge `report`
- Update yearly reports: Purge `report:2024`
- Refresh monthly data: Purge `report:2024:11`

#### Content-Type Tags

Organize by content type:

```yaml
cache:
  ttl: 3600
  tags:
    - content:${input.contentType}
    - content:${input.contentType}:${input.id}
    - category:${input.category}
```

**Use cases:**
- Republish all blog posts: Purge `content:blog`
- Update specific article: Purge `content:blog:123`
- Refresh category: Purge `category:technology`

### Integration with Webhooks

Combine cache tags with webhooks for automatic invalidation:

```yaml
webhooks:
  - path: "/user-updated"
    ensemble: purge-user-cache
    auth:
      type: signature
      secret: ${env.WEBHOOK_SECRET}
```

```typescript
// members/purge-user-cache/index.ts
export default async function purgeUserCache({ input, env }) {
  const { userId } = input;

  // Purge all cache entries for this user
  await fetch(
    `https://api.cloudflare.com/client/v4/zones/${env.CF_ZONE_ID}/purge_cache`,
    {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${env.CF_API_TOKEN}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        tags: [`user:${userId}`]
      })
    }
  );

  return { purged: `user:${userId}` };
}
```

### Best Practices for Cache Tags

<AccordionGroup>
  <Accordion title="Use Consistent Naming" icon="tag">
    Establish naming conventions for tags across your application:
    - `user:${id}` for user-specific data
    - `org:${id}` for organization data
    - `content:${type}:${id}` for content
    - `api` for external API responses
  </Accordion>

  <Accordion title="Balance Granularity" icon="layer-group">
    Too few tags: Invalidate more than necessary
    Too many tags: Complex management, higher overhead

    Aim for 3-7 tags per cache entry that represent different invalidation scenarios.
  </Accordion>

  <Accordion title="Document Tag Strategy" icon="book">
    Maintain documentation of your tag hierarchy:
    - What each tag represents
    - When to purge each tag
    - Tag dependencies and relationships
  </Accordion>

  <Accordion title="Monitor Tag Usage" icon="chart-bar">
    Track which tags are purged most frequently to optimize your caching strategy:
    - Frequently purged tags might need shorter TTLs
    - Rarely purged tags can have longer TTLs
  </Accordion>
</AccordionGroup>

### Cloudflare Zone Configuration

To use cache tags, ensure your Cloudflare zone is properly configured:

```toml
# wrangler.toml
[vars]
CF_ZONE_ID = "your-zone-id"

[secrets]
CF_API_TOKEN = "your-api-token-with-cache-purge-permissions"
```

**Required API Token Permissions:**
- Zone > Cache Purge > Edit

## Cache Configuration Examples

### API Member with Cache

```yaml
- member: fetch-pricing
  type: API
  config:
    url: "https://api.example.com/pricing"
    method: GET
  cache:
    ttl: 3600  # Cache API responses
```

### Think Member with AI Gateway

```yaml
- member: generate-description
  type: Think
  config:
    provider: openai
    model: gpt-4o
    routing: cloudflare-gateway  # Gateway provides caching
    temperature: 0.7
  cache:
    ttl: 7200  # Additional KV cache layer
```

### Data Member with Short Cache

```yaml
- member: get-live-count
  type: Data
  config:
    storage: d1
    operation: query
    query: "SELECT COUNT(*) FROM users"
  cache:
    ttl: 30  # Short cache for live data
```

### Function Member with Conditional Cache

```yaml
- member: calculate-metrics
  type: Function
  cache:
    ttl: ${input.cached ? 3600 : 0}  # User controls caching
```

### HTML Member with Components

```yaml
- member: render-page
  type: HTML
  template:
    inline: |
      {{> templates/components/header}}  # Component cached for 1 hour
      <main>{{content}}</main>
      {{> templates/components/footer}}  # Component cached for 1 hour
  data:
    content: "Page content here"
```

Components loaded via `templates/` URIs are automatically cached. See [Component Caching](#component-caching) below.

## Component Caching

Components (templates, prompts, queries, configs, forms, pages) loaded via the ComponentLoader use Conductor's standard caching system.

### Default Component Caching

All components are cached for 1 hour by default:

```typescript
import { createComponentLoader } from '@ensemble-edge/conductor';

const componentLoader = createComponentLoader({
  kv: env.COMPONENTS,
  cache: conductorCache,
  logger: conductorLogger
});

// Loads from KV, caches for 1 hour
const header = await componentLoader.load('templates/components/header@v1.0.0');
```

### Custom Component Cache Configuration

Override cache behavior per component:

```typescript
// Cache for 24 hours (static content)
const footer = await componentLoader.load('templates/components/footer@v1.0.0', {
  cache: { ttl: 86400 }
});

// Cache for 5 minutes (dynamic content)
const news = await componentLoader.load('templates/components/news@latest', {
  cache: { ttl: 300 }
});

// Bypass cache (force fresh load)
const liveData = await componentLoader.load('templates/components/live-data@latest', {
  cache: { bypass: true }
});
```

### Component Cache Keys

Components use a consistent cache key format:

```
conductor:cache:components:templates/components/header@v1.0.0
conductor:cache:components:prompts/analyze-company@v2.0.0
conductor:cache:components:form://contact@latest
```

The cache key includes:
- **Prefix**: `conductor:cache:components:`
- **Protocol**: `templates/`, `prompts/`, `query://`, etc.
- **Path**: Component path
- **Version**: Explicit version or `@latest`

### Component Cache Invalidation

**Per-Version Caching**: Each version is cached independently
```typescript
// These use separate cache entries
await componentLoader.load('templates/header@v1.0.0');
await componentLoader.load('templates/header@v2.0.0');
```

**Manual Invalidation**:
```typescript
await componentLoader.invalidateCache('templates/components/header@v1.0.0');
```

**Version Updates**: Deploy new version without clearing cache
```bash
# Old version still cached
edgit tag create header v1.1.0
edgit deploy set header v1.1.0 --to production

# v1.0.0 cache remains, v1.1.0 starts fresh
```

### Component Cache Strategies

**Static Components (Long TTL)**:
```typescript
// Headers, footers, layouts - rarely change
await componentLoader.load('templates/layouts/main@v1.0.0', {
  cache: { ttl: 86400 } // 24 hours
});
```

**Dynamic Components (Short TTL)**:
```typescript
// News, metrics, live data - changes frequently
await componentLoader.load('templates/components/stock-ticker@latest', {
  cache: { ttl: 60 } // 1 minute
});
```

**Volatile Components (Bypass Cache)**:
```typescript
// Testing, forced updates, real-time requirements
await componentLoader.load('templates/components/debug@latest', {
  cache: { bypass: true }
});
```

### Component Caching in HTML Member

The HTML member automatically integrates with ComponentLoader:

```yaml
flow:
  - member: render-dashboard
    type: HTML
    template:
      inline: |
        {{> templates/components/header@v1.0.0}}
        <div class="metrics">
          {{> templates/components/metrics@latest}}
        </div>
        {{> templates/components/footer@v1.0.0}}
    data:
      pageTitle: "Dashboard"
```

**Caching Behavior**:
- `header@v1.0.0`: Cached for 1 hour (default)
- `metrics@latest`: Cached for 1 hour (default)
- `footer@v1.0.0`: Cached for 1 hour (default)

For custom cache control, load components programmatically:

```typescript
const metrics = await componentLoader.load('templates/components/metrics@latest', {
  cache: { ttl: 300 } // 5 minutes for dynamic metrics
});

// Pass pre-loaded content to template
const result = await htmlMember.execute({
  input: {
    data: {
      metricsContent: metrics
    }
  }
});
```

## Best Practices

### 1. Start with Longer TTLs

```yaml
# ‚úÖ Start long, reduce if stale data is an issue
cache:
  ttl: 3600

# ‚ùå Don't start too short
cache:
  ttl: 5  # Cache overhead might exceed benefits
```

### 2. Cache Expensive Operations

```yaml
# ‚úÖ Cache AI calls (expensive)
- member: generate-summary
  cache:
    ttl: 3600

# ‚ùå Don't cache trivial operations
- member: format-date
  # No cache needed - operation is instant
```

### 3. Use AI Gateway for AI Calls

```yaml
# ‚úÖ Route through gateway for persistent cache
config:
  routing: cloudflare-gateway

# ‚ùå Don't bypass gateway without reason
config:
  routing: direct  # Misses gateway cache
```

### 4. Cache Components Appropriately

```typescript
// ‚úÖ Long TTL for static components
await componentLoader.load('templates/layouts/main@v1.0.0', {
  cache: { ttl: 86400 } // 24 hours
});

// ‚úÖ Short TTL for dynamic components
await componentLoader.load('templates/components/news@latest', {
  cache: { ttl: 300 } // 5 minutes
});

// ‚ùå Don't bypass cache unnecessarily
await componentLoader.load('templates/header@v1.0.0', {
  cache: { bypass: true } // Only for testing/forced updates
});
```

### 5. Monitor Cache Hit Rates

```typescript
// Track effectiveness
const metrics = await executor.executeEnsemble(ensemble, input);
console.log(`Cache hit rate: ${metrics.cacheHitRate}%`);

// Adjust TTL based on data
if (metrics.cacheHitRate < 50) {
  // Consider increasing TTL
}
```

### 5. Consider Cache Size Limits

KV has size limits (25 MB per value):

```yaml
# ‚úÖ Good - reasonable size
- member: generate-summary
  cache:
    ttl: 3600

# ‚ö†Ô∏è Warning - might exceed limits
- member: fetch-entire-database
  cache:
    ttl: 3600  # Result might be too large
```

### 6. Use Namespace Prefixes

Organize cache keys by environment:

```typescript
// Automatic prefix based on environment
const cacheKey = `conductor:${env.ENVIRONMENT}:${memberName}:${hash}`;

// production: conductor:prod:analyze:a3f8...
// staging: conductor:staging:analyze:a3f8...
```

### 7. Enable Cache Warming for Critical Routes

Pre-populate cache for high-traffic endpoints to ensure fast first-request performance:

```yaml
# ‚úÖ Warm critical pages
- member: homepage
  cache:
    ttl: 3600
    warming: true
    priority: critical

# ‚úÖ Warm frequently accessed APIs
- member: get-pricing
  cache:
    ttl: 7200
    warming: true
    priority: high

# ‚ùå Don't warm rarely accessed routes
- member: admin-dashboard
  cache:
    ttl: 3600
    # No warming needed - low traffic
```

**Benefits:**
- Eliminate cold start latency
- Ensure consistent performance
- Reduce load on origin services
- Improve user experience

### 8. Use Cache Tags for Smart Invalidation

Organize cache entries with tags for targeted purging:

```yaml
# ‚úÖ Tag related cache entries
- member: get-user-data
  cache:
    ttl: 3600
    tags:
      - user:${input.userId}
      - profile

# ‚úÖ Purge by tag when data changes
# Invalidate all cache for user:123
# instead of clearing entire cache

# ‚ùå Don't use too many tags
cache:
  tags:
    - tag1
    - tag2
    - tag3
    - tag4
    - tag5
    - tag6
    - tag7  # Too many - stick to 3-7 meaningful tags
```

**When to use tags:**
- User-specific data that needs coordinated invalidation
- Content that changes together (e.g., all blog posts)
- Hierarchical data (organization > team > user)
- Time-based content (reports by year/month/day)

## Cost Analysis

### Without Caching

```typescript
// 1000 identical requests
// Cost: 1000 √ó $0.002 = $2.00
// Latency: 1000 √ó 2000ms = 2,000,000ms total

for (let i = 0; i < 1000; i++) {
  await callOpenAI(prompt);  // No cache
}
```

### With Caching

```typescript
// 1000 identical requests with cache
// Cost: 1 √ó $0.002 = $0.002 (99.9% savings)
// Latency: 1 √ó 2000ms + 999 √ó 5ms = 7,000ms total (99.65% faster)

for (let i = 0; i < 1000; i++) {
  await executor.executeEnsemble('analyze', input);  // Cached after first
}
```

**Savings:**
- üí∞ **Cost:** $1.998 saved (99.9%)
- ‚ö° **Time:** 1,993 seconds saved (99.65%)

## Testing with Cache

### Bypass Cache in Tests

```typescript
import { TestConductor } from '@ensemble-edge/conductor/testing';

describe('ensemble with cache', () => {
  it('should bypass cache in tests', async () => {
    const conductor = await TestConductor.create();

    // First call
    const result1 = await conductor.executeEnsemble('analyze', input);

    // Second call - bypasses cache for predictable tests
    const result2 = await conductor.executeEnsemble('analyze', input);

    // Both execute fresh (no cache interference)
    expect(result1).not.toBe(result2);
  });
});
```

### Test Cache Behavior

```typescript
it('should respect cache in production', async () => {
  // Mock KV
  const mockKV = {
    get: vi.fn().mockResolvedValue(null),
    put: vi.fn()
  };

  const executor = new Executor({ env: { CACHE: mockKV }, ctx });

  await executor.executeEnsemble('analyze', input);

  // Verify cache was written
  expect(mockKV.put).toHaveBeenCalled();
});
```

## Debugging Cache Issues

### Check Cache Status

```typescript
const result = await executor.executeEnsemble('analyze', input);

console.log('Cached:', result.cached);
console.log('Cache key:', result.metadata?.cacheKey);
console.log('Execution time:', result.executionTime);
```

### Enable Cache Logging

```yaml
# Add logging member
flow:
  - member: analyze-data
    cache:
      ttl: 3600

  - member: log-cache-status
    input:
      cached: ${analyze-data.cached}
      executionTime: ${analyze-data.executionTime}
```

### Verify Cache Keys

```typescript
// Check what's in cache
const keys = await env.CACHE.list({ prefix: 'conductor:cache:' });
console.log('Cached keys:', keys.keys.map(k => k.name));
```

## Related Documentation

<CardGroup cols={2}>
  <Card
    title="AI Gateway"
    icon="network-wired"
    href="https://developers.cloudflare.com/ai-gateway"
  >
    Cloudflare AI Gateway documentation
  </Card>

  <Card
    title="KV Storage"
    icon="database"
    href="https://developers.cloudflare.com/kv"
  >
    Cloudflare KV documentation
  </Card>

  <Card
    title="Routing Modes"
    icon="route"
    href="/conductor/concepts/routing"
  >
    Learn about routing strategies
  </Card>

  <Card
    title="Performance Guide"
    icon="gauge"
    href="/conductor/guides/deployment"
  >
    Optimize your deployment
  </Card>
</CardGroup>
